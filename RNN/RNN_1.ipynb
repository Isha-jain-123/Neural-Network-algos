{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-MPACBAnUUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbc6a65-d76f-449a-ea78-64f5a671e5ea"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "VOCAB_SIZE=88584\n",
        "\n",
        "MAXLEN=250\n",
        "BATCH_SIZE=64\n",
        "\n",
        "(train_data,train_labels),(test_data,test_labels)=imdb.load_data(num_words=VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dL9H3KxDA8F",
        "outputId": "bfb5240c-ab0a-42f2-8f5b-a181eaee263f"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 22665,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 21631,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 19193,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 10311,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 31050,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 12118,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DBy2tUjDerl"
      },
      "source": [
        "More Preprocessing\n",
        "\n",
        "Since each review is of a different length, we cannot pass it to the network. Hence we follow these steps to make all the lengths equal-\n",
        "\n",
        "\n",
        "*   If the review is greater than 250 words, then trim off the excess words.\n",
        "*   If it is less thsn 250 words, then we add necessary amount of 0's to make it 250.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BU5h9RJDA9a"
      },
      "source": [
        "train_data=sequence.pad_sequences(train_data,MAXLEN)\n",
        "test_data=sequence.pad_sequences(test_data,MAXLEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl-OByXiDBBO",
        "outputId": "44b257d4-4d89-4e26-b001-13934ed30403"
      },
      "source": [
        "train_data[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     1,   194,\n",
              "        1153,   194,  8255,    78,   228,     5,     6,  1463,  4369,\n",
              "        5012,   134,    26,     4,   715,     8,   118,  1634,    14,\n",
              "         394,    20,    13,   119,   954,   189,   102,     5,   207,\n",
              "         110,  3103,    21,    14,    69,   188,     8,    30,    23,\n",
              "           7,     4,   249,   126,    93,     4,   114,     9,  2300,\n",
              "        1523,     5,   647,     4,   116,     9,    35,  8163,     4,\n",
              "         229,     9,   340,  1322,     4,   118,     9,     4,   130,\n",
              "        4901,    19,     4,  1002,     5,    89,    29,   952,    46,\n",
              "          37,     4,   455,     9,    45,    43,    38,  1543,  1905,\n",
              "         398,     4,  1649,    26,  6853,     5,   163,    11,  3215,\n",
              "       10156,     4,  1153,     9,   194,   775,     7,  8255, 11596,\n",
              "         349,  2637,   148,   605, 15358,  8003,    15,   123,   125,\n",
              "          68, 23141,  6853,    15,   349,   165,  4362,    98,     5,\n",
              "           4,   228,     9,    43, 36893,  1157,    15,   299,   120,\n",
              "           5,   120,   174,    11,   220,   175,   136,    50,     9,\n",
              "        4373,   228,  8255,     5, 25249,   656,   245,  2350,     5,\n",
              "           4,  9837,   131,   152,   491,    18, 46151,    32,  7464,\n",
              "        1212,    14,     9,     6,   371,    78,    22,   625,    64,\n",
              "        1382,     9,     8,   168,   145,    23,     4,  1690,    15,\n",
              "          16,     4,  1355,     5,    28,     6,    52,   154,   462,\n",
              "          33,    89,    78,   285,    16,   145,    95], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FKX-zk6FAVv"
      },
      "source": [
        "**Creating the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjcW84NuC7Nd"
      },
      "source": [
        "model=tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE,32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJeFPLQ0FrFD",
        "outputId": "a1699c55-51f1-4253-9238-2579dccfd348"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMSBIPERF-f8"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqxwyLbMFu0g",
        "outputId": "04963c0a-59c7-4292-b1f1-ad141a21fc29"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
        "\n",
        "history=model.fit(train_data,train_labels,epochs=10,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 63s 97ms/step - loss: 0.4261 - acc: 0.8011 - val_loss: 0.3152 - val_acc: 0.8740\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 58s 92ms/step - loss: 0.2382 - acc: 0.9100 - val_loss: 0.2809 - val_acc: 0.8956\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 59s 95ms/step - loss: 0.1853 - acc: 0.9317 - val_loss: 0.3413 - val_acc: 0.8950\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.1480 - acc: 0.9456 - val_loss: 0.2755 - val_acc: 0.8896\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.1265 - acc: 0.9564 - val_loss: 0.3288 - val_acc: 0.8888\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.1132 - acc: 0.9614 - val_loss: 0.2908 - val_acc: 0.8892\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.0952 - acc: 0.9686 - val_loss: 0.3161 - val_acc: 0.8764\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 58s 93ms/step - loss: 0.0842 - acc: 0.9712 - val_loss: 0.3470 - val_acc: 0.8866\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.0786 - acc: 0.9733 - val_loss: 0.4103 - val_acc: 0.8886\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 59s 95ms/step - loss: 0.0689 - acc: 0.9787 - val_loss: 0.3805 - val_acc: 0.8818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoUFxD7-Fu2W",
        "outputId": "ac4b1ffa-1f5c-4b6a-eca8-da1b0369e96f"
      },
      "source": [
        "results=model.evaluate(test_data,test_labels)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 17s 22ms/step - loss: 0.4539 - acc: 0.8590\n",
            "[0.45386210083961487, 0.859000027179718]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8rKC9F5JnWt"
      },
      "source": [
        "Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3m9cQItFu5m",
        "outputId": "88be80ea-823c-44af-c7bd-23fabaa99fa2"
      },
      "source": [
        "word_index=imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens=keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens=[word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens],MAXLEN)[0]\n",
        "\n",
        "text=\"that movie was so amazing, just amazing\"\n",
        "encoded=encode_text(text)\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  12  17  13  35 477  40 477]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XXnpxM4Fu8n",
        "outputId": "b4c21d3f-2620-42b3-a919-a35231c01514"
      },
      "source": [
        "# making a decode function\n",
        "\n",
        "reverse_word_index={value: key for (key,value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "  PAD=0\n",
        "  text=\"\"\n",
        "  for num in integers:\n",
        "    if num!=PAD:\n",
        "      text += reverse_word_index[num]+\" \"\n",
        "\n",
        "  return text[:-1]\n",
        "\n",
        "print(decode_integers(encoded))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that movie was so amazing just amazing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6cP6uqCLJOj",
        "outputId": "ee541172-896a-4ffc-e29f-5cd3d245307e"
      },
      "source": [
        "# now we will make a prediction\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text=encode_text(text)\n",
        "  pred=np.zeros((1,250))\n",
        "  pred[0]=encoded_text\n",
        "  result=model.predict(pred)\n",
        "  print(result[0])\n",
        "\n",
        "positive_review=\"That movie was just so  , it was so good I would watch it again, it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review=\"That movie sucked. I hated it and wouldn't watch it again, was one of the worst things i've ever watched\"\n",
        "predict(negative_review)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6280937]\n",
            "[0.2574846]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMEmru0hLJRk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}